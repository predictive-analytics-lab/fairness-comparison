{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files_race = [\n",
    "    '../results/ICML/adult/gpyt2500_dempar_race.csv',\n",
    "#     '../results/ICML/adult/gpyt500_baseline_and_dempar_race.csv',\n",
    "    '../results/ICML/adult/lr_baseline_and_dempar_race.csv',\n",
    "    '../results/ICML/adult/gpyt2500_baseline_race.csv',\n",
    "    '../results/parity_opp_update_2018-08-28/par_fixed/adult_race_baseline.csv',\n",
    "]\n",
    "csv_files_sex = [\n",
    "    '../results/ICML/adult/gpyt2500_dempar_sex.csv',\n",
    "#     '../results/ICML/adult/gpyt500_baseline_and_dempar_sex.csv',\n",
    "    '../results/ICML/adult/lr_baseline_and_dempar_sex.csv',\n",
    "    '../results/ICML/adult/gpyt2500_baseline_sex.csv',\n",
    "    '../results/parity_opp_update_2018-08-28/par_fixed/adult_sex_baseline.csv',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(csv_files, metric1, metric2=(\"accuracy\", \"Accuracy\"), decimals=3, name_transform=None):\n",
    "    entries = []\n",
    "    for csv_file in csv_files:\n",
    "        for algo_name, df in pd.read_csv(csv_file).groupby('algorithm'):\n",
    "            if name_transform is not None:\n",
    "                algo_name = name_transform(algo_name)\n",
    "                if algo_name is None:\n",
    "                    continue\n",
    "            mean1 = round(df[metric1[0]].mean(), decimals)\n",
    "            std1 = round(df[metric1[0]].values.std(ddof=0), decimals)\n",
    "            mean2 = round(df[metric2[0]].mean(), decimals)\n",
    "            std2 = round(df[metric2[0]].values.std(ddof=0), decimals)\n",
    "            entries += [[algo_name, f\"{mean1:.3f} $\\\\pm$ {std1:.3f}\", f\"{mean2:.3f} $\\\\pm$ {std2:.3f}\"]]\n",
    "    return pd.DataFrame(entries, columns=[\"Algorithm\", metric1[1], metric2[1]]).to_latex(index=False, escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_transform(name):\n",
    "    names = [\n",
    "        'SVM',\n",
    "        'ZafarAccuracy',\n",
    "        'ZafarFairness',\n",
    "    ]\n",
    "    if name in names:\n",
    "        return name\n",
    "    if name.startswith('GPyT'):\n",
    "        if '_av' in name or '_tar_min' in name or '_tar_max' in name:\n",
    "            return\n",
    "        parts = name.split('_')\n",
    "        if 'dem_par' in name:\n",
    "            in_True = parts[4] == \"True\"\n",
    "            optional_s = \", use $s$\" if in_True else \"\"\n",
    "            return f\"FairGP{optional_s}\"\n",
    "        else:\n",
    "            in_True = parts[2] == \"True\"\n",
    "            optional_s = \", use $s$\" if in_True else \"\"\n",
    "            return f\"GP{optional_s}\"\n",
    "    if name.startswith('ULR'):\n",
    "        parts = name.split('_')\n",
    "        if 'dem_par' in name:\n",
    "            in_True = parts[4] == \"True\"\n",
    "            optional_s = \", use $s$\" if in_True else \"\"\n",
    "            return f\"FairLR{optional_s}\"\n",
    "        else:\n",
    "            in_True = parts[2] == \"True\"\n",
    "            optional_s = \", use $s$\" if in_True else \"\"\n",
    "            return f\"LR{optional_s}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "       Algorithm &   Disparate Impact &           Accuracy \\\\\n",
      "\\midrule\n",
      "          FairGP &  0.621 $\\pm$ 0.029 &  0.853 $\\pm$ 0.003 \\\\\n",
      " FairGP, use $s$ &  0.891 $\\pm$ 0.049 &  0.850 $\\pm$ 0.003 \\\\\n",
      "          FairLR &  0.728 $\\pm$ 0.038 &  0.844 $\\pm$ 0.003 \\\\\n",
      " FairLR, use $s$ &  1.025 $\\pm$ 0.074 &  0.843 $\\pm$ 0.002 \\\\\n",
      "              LR &  0.570 $\\pm$ 0.025 &  0.846 $\\pm$ 0.003 \\\\\n",
      "     LR, use $s$ &  0.743 $\\pm$ 0.028 &  0.846 $\\pm$ 0.002 \\\\\n",
      "              GP &  0.555 $\\pm$ 0.023 &  0.853 $\\pm$ 0.002 \\\\\n",
      "     GP, use $s$ &  0.503 $\\pm$ 0.029 &  0.854 $\\pm$ 0.003 \\\\\n",
      "             SVM &  0.605 $\\pm$ 0.019 &  0.859 $\\pm$ 0.002 \\\\\n",
      "   ZafarAccuracy &  1.306 $\\pm$ 0.337 &  0.800 $\\pm$ 0.011 \\\\\n",
      "   ZafarFairness &  0.579 $\\pm$ 0.129 &  0.846 $\\pm$ 0.003 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(csv_files_race, ('DIbinary', \"Disparate Impact\"), name_transform=name_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "       Algorithm &   Disparate Impact &           Accuracy \\\\\n",
      "\\midrule\n",
      "          FairGP &  0.645 $\\pm$ 0.035 &  0.846 $\\pm$ 0.004 \\\\\n",
      " FairGP, use $s$ &  0.712 $\\pm$ 0.037 &  0.845 $\\pm$ 0.003 \\\\\n",
      "          FairLR &  0.666 $\\pm$ 0.030 &  0.839 $\\pm$ 0.003 \\\\\n",
      " FairLR, use $s$ &  0.711 $\\pm$ 0.029 &  0.838 $\\pm$ 0.003 \\\\\n",
      "              LR &  0.333 $\\pm$ 0.023 &  0.847 $\\pm$ 0.002 \\\\\n",
      "     LR, use $s$ &  0.339 $\\pm$ 0.019 &  0.847 $\\pm$ 0.002 \\\\\n",
      "              GP &  0.320 $\\pm$ 0.028 &  0.854 $\\pm$ 0.003 \\\\\n",
      "     GP, use $s$ &  0.311 $\\pm$ 0.019 &  0.854 $\\pm$ 0.002 \\\\\n",
      "             SVM &  0.261 $\\pm$ 0.015 &  0.857 $\\pm$ 0.003 \\\\\n",
      "   ZafarAccuracy &  1.218 $\\pm$ 0.375 &  0.793 $\\pm$ 0.008 \\\\\n",
      "   ZafarFairness &  0.345 $\\pm$ 0.094 &  0.846 $\\pm$ 0.003 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(csv_files_sex, ('DIbinary', \"Disparate Impact\"), name_transform=name_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
